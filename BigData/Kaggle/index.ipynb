{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<big style=\"font-size:2em;color:yellow;background-color:black;\">\n",
    "**Ãµ|o**   <big style=\"font-size:0.7em;color:brown;background-color:white;padding:-2pt\"> \n",
    "&nbsp;Welcome To the World of Data Science, <small>2017/9/23</small> &nbsp;\n",
    "</big>\n",
    "</big>\n",
    "\n",
    "<code style=\"background-color:lightblue;\"> Your little step, should be Big power of ML in the future.</code>\n",
    "\n",
    "<div>\n",
    "**1.** Basics of Python\n",
    "<code style=\"color:brown;font-family:chalkboard;font-size=1.6em;\">\n",
    "    \\# ...                   : Comments\n",
    "    import xxx            : load Python package, xxx\n",
    "    import xxx as x       : load xxx and assign it as nickname x\n",
    "    from xxx import f     : load x.f function/submodule \n",
    "\n",
    "   %matplotlib inline    : display the graphical output coincide\n",
    "</code>\n",
    "\n",
    "**2.** <big>Goals of this demo</big>\n",
    "  - load/collect Data\n",
    "  - Data Washing, for instance, NaN, Null Value,\n",
    "  - Data Exploring,   \n",
    "  - Modeling, logistic Model and Stochastic Gradient Decendent Model (**SGD**)\n",
    "  - Evaluation, Prediction, and make a report. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python packages for calculation\n",
    "import numpy as np\n",
    "# python packages for database manipulation\n",
    "import pandas as pd\n",
    "# python visualization packages for statistics\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "# the main Python visualisation package\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# One of the best features of Jupyter notebook environment, output the visualisation frontend\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data, Here we come\n",
    "---\n",
    "Data is alawys packed together to spread and be shared; one of popular format is called \"CSV\" format, plain text and displayed line by line and each column seperated by common mark:\n",
    "1. open it if already exists,\n",
    "- otherwise download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create table of features\n",
    "column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', \\\n",
    "                'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', \\\n",
    "                'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n",
    "cvsfile = \\\n",
    "  'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "if os.path.isfile(\"c2.1.1.1.csv\"):\n",
    "   df = pd.read_csv(\"c2.1.1.1.csv\", index_col=0, dtype=int) \n",
    "else:\n",
    "   # download data from remote database hosted at Universition of California, Irvine\n",
    "   df = pd.read_csv(cvsfile, names = column_names )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data is the native download, drop the useless data and save it for next use:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# replace \"?\" with \"nan\n",
    "df = df.replace(to_replace='?', value=np.nan)\n",
    "# delete any data owning \"nan\" value in certaincolumn\n",
    "df = df.dropna(how='any')\n",
    "df.to_csv(\"c2.1.1.1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us obserse the data which we just loaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the man of package, function or others: put \"?\" ahead of behind the command\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data array\n",
    "---\n",
    "$x_0,x_1,x_2,\\cdots$\n",
    "\n",
    "$\\cdots,x_{-3},x_{-2},x_{-1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first five data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# basic statistics for each features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list number of total data and number of features of each data \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Final feature</big>, **Class**: 2 for benign, 4 for malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"Class2\"] = df.Class.map({2: \"B\", 4: \"M\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.drop('Class2',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "IPywidgets\n",
    "---\n",
    "```\n",
    "Awesome sub-project in Jupyter: enhance the interactivity between UI and Programming itself!\n",
    "```\n",
    "Although the last version has come to 7.x.x, interested users should be urged to install the verion-6.x to prevant the confilicts between other third-party packages and ipywidgets.\n",
    "\n",
    "Installation, by anaconda, a). UI installation b). by Python \"pip\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Display by IPyWidgets Design\n",
    "---\n",
    "There are two options availabe:\n",
    "\n",
    "a). **Class** option: 3-category, \"All\", \"2\" for B, \"4\" for M;<br>\n",
    "b). **number** of items: with slider bar, determine the size of data displayed simulataneously: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['All']+sorted(df['Class'].unique().tolist())\n",
    "\n",
    "def view2(Class='',numbers=3):\n",
    "    if Class=='All': return df.head(numbers)\n",
    "    return df[df['Class']==Class].head(numbers)\n",
    "    #return df.head(y)\n",
    "a_slider = widgets.IntSlider(min=3, max=df.shape[0], step=1, value=5)\n",
    "b_select =  widgets.Select(options=items)\n",
    "widgets.interact(view2,numbers=a_slider,Class=b_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertion of data\n",
    "---\n",
    "from \"object\" to \"int\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert object to int data on sixth-feature \n",
    "df[df.columns[6]]=df[df.columns[6]].astype(int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"chapter_2.1.1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: **qgrid** not worked with ipywidgets-7.x.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import qgrid\n",
    "#qgrid.nbinstall(overwrite=True)\n",
    "qgrid.set_defaults(remote_js=True, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(df,show_toolbar=True, grid_options={'forceFitColumns': False, 'defaultColumnWidth': 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Explore correlations\n",
    "plt.rcParams['figure.figsize']=(12,8)\n",
    "sns.set(font_scale=1.4)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Partition for Training/Testing set\n",
    "---\n",
    "\n",
    "```\n",
    "          All Data\n",
    " |-----+-----+-----][xxxxx] \n",
    "        75 %         25 %\n",
    "    Train data       test data\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice dataframe by train_test_split in  sklearn.cross_valiation module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 75% randomly chosen data for training and left for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[column_names[1:10]], df[column_names[10]], \\\n",
    "                                                    test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# slice dataframe by train_test_split in  sklearn.cross_valiation module\n",
    "data =df\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 75% randomly chosen data for training and left for testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[column_names[1:10]], data[column_names[10]], \\ \n",
    "                                                    test_size=0.25, random_state=33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of $X,Y$\n",
    "---\n",
    "$$\\text{Correlation}(X,Y)=\\frac{E(X-\\mu_X)(Y-\\mu_Y)}{\\sigma_X\\sigma_Y}$$\n",
    "\n",
    "used to measure the relation between $X,Y$ statistics, 1 represents \"totally positive related\", -1 represents \"totally negative related\", and 0 \"no relation at all\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12,8)\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "sns.heatmap(df.corr(), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, ```Sample code number```, the first feature, should be nothing matter with other features. Remake the corelation plot again based on the features exluded the first feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=df[column_names[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12,8)\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "sns.heatmap(df1.corr(), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Mean versions of the 10 Core Predictors </h4><br>\n",
    "The below boxplots are of the \"mean\" value for the 10 core features in the dataset.  These are ranked as the most important features in the model we fit (see Feature Importances below) in terms of classifying the breast cancer mass as Malignant (4) or Benign (2). \n",
    "\n",
    "The charts reveal a tendency for the average value of a feature to be generally higher for malignant diagnoses vs. the benign class. This is true for every feature except for <b> Fractal Dimension Mean</b> which shows a flat difference between M and B diagnoses for the mean value of the feature.  <b>Radius Mean</b> on the other hand shows a more distinct distribution for (4) vs. (2) diagnoses, as is subsequently found to be the most important feature according to our fitted Random Forest model further below (see Feature Importances cell[9] &amp; [10] below).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(10,5)\n",
    "diagnosis='Class'\n",
    "f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\n",
    "sns.boxplot(df.columns[10],y=df.columns[0],data=df, ax=ax1, palette='cubehelix')\n",
    "sns.boxplot(df.columns[10],y=df.columns[1],data=df, ax=ax2, palette='cubehelix')\n",
    "sns.boxplot(df.columns[10],y=df.columns[2],data=df, ax=ax3, palette='cubehelix')\n",
    "sns.boxplot(df.columns[10],y=df.columns[3],data=df, ax=ax4, palette='cubehelix')\n",
    "sns.boxplot(df.columns[10],y=df.columns[4],data=df, ax=ax5, palette='cubehelix')\n",
    "f.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\n",
    "sns.boxplot(df.columns[10],y=df.columns[5],data=df, ax=ax1)\n",
    "sns.boxplot(df.columns[10],y=df.columns[6],data=df, ax=ax2)\n",
    "sns.boxplot(df.columns[10],y=df.columns[7],data=df, ax=ax3)\n",
    "sns.boxplot(df.columns[10],y=df.columns[8],data=df, ax=ax4)\n",
    "sns.boxplot(df.columns[10],y=df.columns[9],data=df, ax=ax5)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(10,12)\n",
    "for i in range(len(df.columns)-1):\n",
    "    g = sns.FacetGrid(df, col=df.columns[10], hue=df.columns[10])\n",
    "    g.map(sns.distplot, df.columns[i], hist=True, rug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# category of training data\n",
    "y_train.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# category of test data  \n",
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize data\n",
    "---\n",
    "$$ \\mathbf{X\\Rightarrow \\frac{X-\\mu_X}{\\sigma_X} \\sim Normal(\\mu=0,\\sigma^2=1)}$$\n",
    "Theoretically, there is no effect in our calculation; but it does help to speed up the calculation!\n",
    "\n",
    "Logistical Regression and SGD\n",
    "---\n",
    "1. Linear regression: $\\mathbf{X, (y_X),W,b}=(X_i)_i,(W_i)_i ,(b_i)_i\\to y=\\mathbf{W^TX+b}$;\n",
    "   - $\\mathbf{(X,y_X)}$ real data, $y=\\mathbf{W^TX+b}$ estimated data\n",
    "   - $L=\\sum(\\mathbf{y_X-y})^2$, $L^2$ error\n",
    "   - $ \\min\\limits_{W,b}L\\Rightarrow \\hat{\\! W}, \\hat{\\! b}\\Rightarrow \\hat{\\! y}=\\mathbf{\\hat{\\!W}^TX+\\hat{\\!b}}$ ,\n",
    "     the estimated data for $y_X$.\n",
    "   - $y_X$ is in real range but not two-valued.  \n",
    "- to make the conclusion, 0 for \"no cancer\", 1 for \"yes\", introduce the following logistion function:\n",
    "$$ p(\\mathbf{X})=\\frac{1}{1+e^{-y}}=\\frac{1}{1+e^{-(\\mathbf{W^TX+b})}}$$\n",
    "which transforms\n",
    "$$y\\in(-\\infty,\\infty)\\to [0,1]\\text{ and } [0,1/2)\\to 0 (1/2,1]\\to1$$\n",
    "since the logistic curve arises fast about $x=1/2$ from alomst 0 to 1.\n",
    "3. Maximaize the likelihood function of training data $\\mathbf{(X_i,y_i)}$ by Stochastic Gradient Decendent method, (SGD):\n",
    "$$\\begin{array}{c}\n",
    "     \\mathbf{\\text{argmax}}\\\\\n",
    "     \\mathbf{W}, b\n",
    "   \\end{array}\n",
    "L({\\mathbf{W},b})=\n",
    "\\begin{array}{c}\n",
    "     \\mathbf{\\text{argmax}}\\\\\n",
    "     \\mathbf{W}, b\n",
    "   \\end{array}\n",
    "\\prod_\\mathbf{(X_i,y_i)}p(\\mathbf{X_i})^{y_i}\n",
    "      (1-p(\\mathbf{X_i}))^{1-y_i}$$\n",
    "\n",
    "The best things are that sklearn provides all the functions doing all the calculation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big style=\"font-size:2em;color:yellow;background-color:black;\">\n",
    "**ð|ð¯**   <big style=\"font-size:0.7em;color:brown;background-color:white;padding:-2pt\"> \n",
    "&nbsp;SDG &nbsp;\n",
    "</big>\n",
    "</big>\n",
    "1. differential, difference: $\\mathbf{df=f_x=f'(x) dx\\approx\\vartriangle f(x,h)\\cdot h=\\left(f(x+h)-f(x)\\right)h}$\n",
    "   - $f'(x)=0\\Rightarrow f(x)$ attains maximum or minimum;\n",
    "   - $f'(x)>0\\nearrow$\n",
    "   - $f'(x)<0\\searrow$\n",
    "- $\\mathbf{\\nabla f(X)=(f_1,f_2,\\cdots,f_n)}$\n",
    "  - along $\\mathbf{\\nabla f(X)}$, $\\mathbf{f}$ increases fast;\n",
    "  - along $\\mathbf{-\\nabla f(X)}$, $\\mathbf{f}$ decreases fast;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LogisticRegression and SGDClassifier\n",
    "lr = LogisticRegression()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "# fitting parameter by LogisticRegression \n",
    "lr.fit(X_train, y_train)\n",
    "# make prediction by above fitting\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "\n",
    "# fitting parameters by SGDClassifier\n",
    "sgdc.fit(X_train, y_train)\n",
    "# make prediction by sgdc result\n",
    "sgdc_y_predict = sgdc.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scoring of Tests\n",
    "---\n",
    "<big>\n",
    "\n",
    "\n",
    "|Accuracy|Precision|recall|f1-score|support|\n",
    "|---|---|---|---|\n",
    "|<big>$\\mathbf{\\frac{P(T|T)+P(F|F)}{P(\\Omega)}}$</big>|<big>$\\mathbf{\\frac{P(T|T)}{P(\\Omega|T)}}$</big>|<big>$\\mathbf{\\frac{P(T|T)}{P(T|T)+P(F|F)}}$</big>| <big><big>$\\frac{2}{1/\\text{Precision}+1/\\text{Recall}}$</big></big>|freqs|\n",
    "|||||\n",
    "\n",
    "1. Accuracy: \n",
    "- Precision:\n",
    "- Recall:\n",
    "- f1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If want to competition, have to return report  \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Logistic Model Accuracy\n",
    "print('Accuracy of LR Classifier:', lr.score(X_test, y_test))\n",
    "# three indexes from LogisticRegression\n",
    "print(classification_report(y_test, lr_y_predict, target_names=['Benign', 'Malignant']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # SGD accuracy\n",
    "print('Accuarcy of SGD Classifier:', sgdc.score(X_test, y_test))\n",
    "# its three indexes\n",
    "print(classification_report(y_test, sgdc_y_predict, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Self-Training\n",
    "---\n",
    "Duplicate the procedures for the [Breast Cancer Data from Kaggle](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
