{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kaggle Competition</h1>\n",
    "\n",
    "In this lecture, we want to get the better or best score in competiotion of Kaggle data.\n",
    "\n",
    "Windows users have to install the `Xgboost` package; download from <a href=\"https://www.lfd.uci.edu/~gohlke/pythonlibs/\">binary Python Packages</a> the suitable package and install as follows in anaconda Python console or system text environment:\n",
    "```shell\n",
    "> pip install certainPythonPackage.whl\n",
    "```\n",
    "where <font style=\"color:brown;\">certainPythonPackage.whl</font> is the package to be instelled in one's Windows system, for instance, <font style=\"color:brown;\">xgboost‑0.6‑cp36‑cp36m‑win_amd64.whl</font> is for Windows 64 system and for Python-3.6.x. \n",
    "\n",
    "<p>\n",
    "<big style=\"font-size:2em;color:yellow;background-color:black;\">\n",
    "**õ|o**   <big style=\"font-size:0.7em;color:brown;background-color:white;padding:-2pt\"> \n",
    "&nbsp;Self-Training&nbsp;\n",
    "</big>\n",
    "</big>\n",
    "\n",
    "Also install 1&deg;) graphviz 2&deg;) OpenCV for late use, for instance <font style=\"color:brown;\">opencv_python‑3.3.1‑cp36‑cp36m‑win_amd64.whl</font>.\n",
    "\n",
    "\n",
    "**Install from Scratch,**\n",
    "download source, from https://github.com/dmlc/xgboost, make and install within text console\n",
    "\n",
    "```    \n",
    "   # Linux system\n",
    "   > git clone --recursive https://github.com/dmlc/xgboost\n",
    "   > cd xgboost; make -j4\n",
    "\n",
    "   # Mac system\n",
    "   > git clone --recursive https://github.com/dmlc/xgboost\n",
    "   > cd xgboost; cp make/minimum.mk ./config.mk; make -j4\n",
    " \n",
    "   # install Python package\n",
    "   > cd python-package; sudo python setup.py install\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from <a href=\"https://www.kaggle.com/c/titanic\">Kaggle</a>, save, and open it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "test=pd.read_csv(\"data/Titanic/test.csv\")\n",
    "train=pd.read_csv(\"data/Titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "---\n",
    "As a simple example, only few features were considered here, Pclass, including Age, Sex, Fare, and Embraked_[SQB] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data0(titanic):#填充空数据 和 把string数据转成integer表示\n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "    \n",
    "    # sex\n",
    "    titanic[\"Sex\"] = titanic[\"Sex\"].apply(lambda x: 1 if x == \"male\" else 0)\n",
    "\n",
    "    titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "    x_OneHot_df = pd.get_dummies(data=train,columns=[\"Embarked\" ])\n",
    "    return x_OneHot_df\n",
    "\n",
    "# 对数据进行清洗\n",
    "train_data = clean_data0(train)\n",
    "test_data = clean_data0(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted features for this lecture only\n",
    "features = [\"Pclass\", \"Sex\",\"Fare\", \"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data[features]\n",
    "y_train=train_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_data[features]\n",
    "y_test=test_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('The accuracy of Decision Tree Classifier on testing set:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big style=\"font-size:2em;color:yellow;background-color:black;\">\n",
    "**o|o**   <big style=\"font-size:0.7em;color:brown;background-color:white;padding:-2pt\"> \n",
    "Kaggle Submission\n",
    "</big>\n",
    "</big>\n",
    "\n",
    "a°). Predict, b°). submission, c°). save to the specified data format; if not satisfied its format, the data should be not evaluated by Kaggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_y_predict=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice X_test doesn't own the feature 'PassengerId', but raw test_data does\n",
    "\n",
    "clf_submission=pd.DataFrame({'PassengerId':test_data['PassengerId'],'Survived':clf_y_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_submission.to_csv('data/clf_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big style=\"font-size:2em;color:yellow;background-color:black;\">\n",
    "**o|o**   <big style=\"font-size:0.7em;color:brown;background-color:white;padding:-2pt\"> \n",
    "    Structure of Decision Tree Algorithm\n",
    "</big>\n",
    "</big>\n",
    "\n",
    "a°). measurement,entropy, or gini (defaulted) b°). convert result to dot format; this step requires \"pydot\", installed it within anaconda shell environment (?):\n",
    "```\n",
    "> conda install -c anaconda pydot\n",
    "```\n",
    "c°). save to the specified data format; if not satisfied its format, the data should be not evaluated by Kaggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_en = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "clf_en.fit(X_train, y_train)\n",
    "print('The accuracy of Decision Tree Classifier on testing set:', clf_en.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf,out_file='tree.dot')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from IPython.display import SVG,Image\n",
    "#import pydot\n",
    "from sklearn.externals.six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tree1.dot\", 'w') as f:\n",
    "  f = tree.export_graphviz(clf, feature_names = X_test.columns, out_file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = Source( tree.export_graphviz(clf, out_file=None, filled=True, rotate=True, rounded=True, feature_names=X_test.columns))\n",
    "Image(graph.pipe(format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = Source( tree.export_graphviz(clf, out_file=None, filled=True, rotate=True, rounded=True, feature_names=X_test.columns))\n",
    "SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO() \n",
    "tree.export_graphviz(clf, out_file=dot_data, rotate=True, feature_names=X_test.columns,filled=True, \n",
    "                                 rounded=True) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph[0].write_png('tree.png') \n",
    "from IPython.core.display import Image \n",
    "Image(filename='tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = Source( tree.export_graphviz(clf_en, out_file=None, filled=True, rotate=True, rounded=True, feature_names=X_test.columns))\n",
    "SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Source( tree.export_graphviz(clf, out_file=None, filled=True, rotate=True, rounded=True, feature_names=X_test.columns))\n",
    "graph.format = 'png'\n",
    "graph.render('dtree_render',view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dtree_render.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total= len(X_train.Pclass)\n",
    "entropy_pclass=0\n",
    "gani_pclass=0\n",
    "expect_pclass=0\n",
    "gain_pclass=0\n",
    "\n",
    "for i in X_train.Pclass.unique():\n",
    "    num=sum(X_train['Pclass']==i)\n",
    "    gani_pclass += total\n",
    "    print(\"Pclass %s has %d persons\" %(i,num ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurement\n",
    "---\n",
    "- Entropy: $-\\sum_i p_i\\log_2 p_i$\n",
    "- gini: $1-\\sum_i p_i^2$ computed faster than above since it is sum of terms od square\n",
    "$$\\log |1+x|\\approx x-x^2/2+o(x^2)$$\n",
    "\n",
    "**ID3 Alogrithm.** In the first level:\n",
    "\\begin{eqnarray}\n",
    "I(549,342)&:&\\text{entropy}&=& -\\frac{549}{891}\\log_2\\frac{549}{891}-\\frac{342}{891}\\log_2\\frac{342}{891}\\approx0.961\\\\\n",
    "            && \\text{gini}&=& 1-\\left(\\frac{549}{891}\\right)^2-\\left(\\frac{342}{891}\\right)^2\\approx0.473\n",
    "\\end{eqnarray}\n",
    "And \n",
    "```\n",
    "             not Survived     Survived      Total\n",
    "Pclass 1:        136             80          216\n",
    "Pclass 2:         87             97          184\n",
    "Pclass 3:        119            372          491\n",
    "                                             891\n",
    "```\n",
    "This got\n",
    "$$ E_{Pclass}= \\frac{216}{891}I(136,80)+\\frac{184}{891}I(87,97)+\\frac{491}{891}I(119,372)=0.8769$$\n",
    "And \n",
    "$$ \\text{Gain}_{\\color{brown}{Pclass}}=I(549,342)-E_{Pclass}\\approx0.08383$$\n",
    "should be **greater** than others' Gain function and this suggests that the feature, **Pclass**, is on the top of the tree.\n",
    "\n",
    "Result\n",
    "---\n",
    "The top stem in the tree is\n",
    "<pre style=\"color:brown;\">\n",
    "[Pclass ≤ 2.5] yes → [Fare ≤ 13.649] yes → [Fare ≤ 7.75] yes ─► non-survival are 12, survival is 0.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def I(a,b):\n",
    "    ab=a+b\n",
    "    return -a/ab*log2(a/ab)-b/ab*log2(b/ab)\n",
    "def E(a,b,s=891):\n",
    "    return (a+b)*I(a,b)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Pclass=E(136,80)+E(87,97)+E(119,372)\n",
    "E_Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "print('The accuracy of Random Forest Classifier on testing set:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rfc,X_train, y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf,X_train, y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While rfc fitted, gte out the result from ```rfc.estimators_``` and make visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO() \n",
    "tree.export_graphviz(rfc.estimators_[0], out_file=dot_data, rotate=True, feature_names=X_test.columns,filled=True, \n",
    "                                 rounded=True) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph[0].write_png('rfctree.png') \n",
    "\n",
    "Image(filename='rfctree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()\n",
    "\n",
    "xgbc.fit(X_train, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc2 =XGBClassifier(learning_rate=0.1, max_depth=4, silent=True, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc2.fit(X_train, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test = {\n",
    "    'learning_rate': (0.01,0.05,0.1),\n",
    "    'n_estimators': list(range(30, 50, 2)),\n",
    "    'max_depth': list(range(2, 7, 1))\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = xgbc2, param_grid = param_test, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.grid_scores_, grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc2 =XGBClassifier(learning_rate=0.01, max_depth=6, gamma=0., silent=True, objective='binary:logistic')\n",
    "xgbc2.fit(X_train, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(xgbc2)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(150,100)o\n",
    "\n",
    "fig.savefig(\"imgs/xgbtree.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# change orientation\n",
    "plot_tree(xgbc2,num_trees=0, rankdir='LR')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(150,100)\n",
    "fig.savefig(\"imgs/xgbtree_h.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
