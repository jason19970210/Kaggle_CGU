{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forensic Investigations with Python\n",
    "===\n",
    "\n",
    "In February 2005, Wichita police forensic investigator Mr. Randy Stone unraveled the  nal clues of a 30-year-old mystery. A couple of days earlier, KSAS Television station had handed the police a 3.5”  floppy disk they had received from the infamous BTK (Bind, Torture, Kill) Killer. Responsible for at least 10 murders from 1974 to 1991, the BTK Killer eluded capture while repeatedly taunting the police and his victims. On February 16th, 2005, the BTK Killer sent the television station a 3.5” disk with communication instructions. Among these instructions, the disk contained a file named **Test.A.rtf**. (Regan, 2006). While the  file contained instructions from the BTK Killer, it also contained something else: *metadata*. Embedded in the Microsoft proprietary Rich Text Format (RTF), the  file contained the *first name* of the BTK Killer and the *physical location* at which the user had last saved the file.\n",
    "\n",
    "This narrowed the investigation to a man named **Denis** at the local Wichita Christ Lutheran Church. Mr. Stone verified that a man named **Denis Rader** served as a church officier at the Lutheran Church (Regan, 2006). With this information, police requested a warrant for a DNA sample from the medical records of Denis Rader’s daughter (Shapiro, 2007). The DNA sample confirmed what Mr. Stone already knew — **Denis Rader was the BTK Killer**. A 31-year investigation that had exhausted 100,000 man hours ended with Mr. Stone’s examination of metadata (Regan, 2006)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECOVER DELETED ITEMS\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Study\n",
    "===\n",
    "Anonymous’ Metadata Fail\n",
    "---\n",
    "On December 10, 2010, the hacker group **Anonymous** posted a press release outlining the motivations behind a recent attack named *Operation Payback* (Prefect, 2010). Angry with the companies that had dropped support for the Web site WikiLeaks, Anonymous called for retaliation by performing a distributed denial of service (DDoS) attack against some of the parties involved. The hacker posted the press release *unsigned* and without attribution. Distributed as a Portable Document Format (PDF)  file, the press release contained metadata. In addition to the program used to create the document, the PDF metadata contained the name of the author, **Mr. Alex Tapanaris**. Within days, Greek police arrested Mr. Tapanaris (Leyden, 2010)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File can be downloaded from  http://www.wired.com/images_blogs/threatlevel/2010/12/ANONOPS_The_Press_Release.pdf.\n",
    "\n",
    "Part of content is read by general editor  and in binary format as follows:\n",
    "<pre  style=\"color:brown\">\n",
    "PDF-1.4\n",
    "%Ã¤Ã¼Ã¶Ã&lt;9f&gt;\n",
    "2 0 obj\n",
    "&lt;&lt;/Length 3 0 R/Filter/FlateDecode&gt;&gt;\n",
    "stream\n",
    "x&lt;9c&gt;¥[I&lt;8b&gt;,¹^Q¾¿_QgC×hËL%^T^E]Ý&lt;95&gt;`ß^F^Z|0&gt;y^CÃØÌ\\ü÷­X^T^QRª2Û&lt;98&gt;^Gýª2µ&lt;84&gt;\"¾X^Uå®þò&lt;9f&gt;^_¿^\\ù7­Ó5]r\n",
    "&lt;97&gt;ßþvùãï.ÿâçîòÛ?~&lt;¾~Ló5_^V¿\\§Ë×_/?mþ^RÃåëï^?º9^?÷7^Wîñæ¢^K.Á·è¦{¸¹ùþV¾,ô^L&lt;87&gt;%|2ÝóÍå»O7·ÂÓw|ú^NSpè&lt;83&gt;^^^?Ð^?&lt;9f&gt;úv½ÿùë^O?&lt;9e&gt;_?~^^Q7ç¥Ò^V^RÑö¼¿ÕM¶ûL&lt;9f&gt;¼ó¾|&lt;98&gt;&lt;80&gt;^DX9ùPÖö^Qþ$~2É&lt;93&gt;p^?Ã&lt;8f&gt;&lt;87&gt;^['w&lt;8d&gt;´u¸xÞÚ^WfD&lt;97&gt;ÊaaÉ^Yø&lt;93&gt;î&lt;93&gt;+ü^@jry&lt;97&gt;ï^KPôæ#^\\Ï#^C^_÷·^YF^_nç&lt;9d&gt;lÆ2ø(^K^VÚ^WàVáS&lt;80&gt;&lt;83&gt;Ï7&lt;92&gt;Âv^?Ë7~[¶q°^MHÆ!k§új+s&lt;80&gt;9@Ý&lt;93&gt;H^DÎ'xÿ&lt;82&gt;^Z?¥k^X&lt;90&gt;Søûð^Aù^GÇ&lt;9f&gt;`Õ&lt;93&gt;&lt;95&gt;òR888Ø^LìÇCùD`^H7&gt;^\\&lt;9d&gt;&lt;85&gt;&gt;g^Z2áI^RÀËßS$^Fø&lt;99&gt;&lt;89&gt;Xh®§¥Êcæ^B&lt;9d&gt;¿\"6Ü^ZNâGÚ&lt;84&gt;^^^W¹&lt;95&gt;&lt;93&gt;^AßÖ{å«Ï&lt;85&gt;}ExÞ3^A8Ð¯üÖ^SC£÷&lt;Ó®&lt;87&gt;ÛD3^Oi~W^Y^D~^DH&lt;99&gt;e×^T^@ISE^R¿ò^KkJ!æ^@E1_&lt;97&gt;^]·aÕ¯^?¾DÝ´ÎEØ&lt;9d&gt;&nbsp;^]iûÖ&nbsp;^GQ¥&lt;&lt;8a&gt;7ÿàã^QüO&lt;88&gt;F&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "4âÀá&lt;8c&gt;U&lt;82&gt;AR&lt;8e&gt;û&nbsp;&nbsp;&nbsp;\n",
    "4¸ÌDN%·^Y&nbsp;Té&lt;81&gt;ú×©EQP]&gt;Y^Rø.Ó&lt;87&gt;ºG¶kÔ1HQ.ï^^&lt;87&gt;Ú9Íù:÷|úÀ^C^PE+ÙÁø^]^A¾­h6ÞrÅ^?öï²B^N=Hó*/Þ^Eìï^LÿÔ¼§&lt;89&gt;ðpÆs&lt;9b&gt;W&lt;95&gt;õfo&lt;92&gt;³ÿìy!´¬&lt;9e&gt;çéR++^ZbÃ¬OÚ÷D»º{¿â&gt;^Eê9Êw5if^QÖ©&lt;8d&gt;H&lt;9b&gt;D&lt;98&gt;LcË&amp;ä&lt;81&gt;à&lt;89&gt;þª&lt;8d&gt;3ô&lt;86&gt;&lt;8a&gt;&lt;83&gt;À^TÒw^Z{¤N#¹&lt;9f&gt;)T±&lt;9e&gt;¹·wÌX¢·&lt;9c&gt;&lt;85&gt;&lt;8d&gt;^A*^P1.VÏº&lt;90&gt;ÅðKªÓ^@D³&gt;T¾ù%Êc^D7&nbsp;\n",
    "ý^Eºi6^L&lt;9f&gt;Ê¦^[^M&lt;9b&gt;^FÛ^VÂ\"Í&lt;87&gt;^WsÖ­3ã^],²¬^Fÿ^W&lt;9f&gt;h^X+&lt;80&gt;º'¿^_k^L&lt;&lt;83&gt;¿^[ÐcØ/áôôl±P=Þï&lt;8d&gt;Z5k«ã)ÌyTÃ^V\n",
    "8!&lt;87&gt;Ú-&lt;8c&gt;¨=´·{y&lt;9f&gt;^A$ù^^^^ç^F^C^]&lt;9a&gt;J^K¾ù&lt;95&gt;Y$Q&lt;8d&gt;Ñßêv&lt;8a&gt;³^B;&lt;9e&gt;^Dhì&lt;8d&gt;&lt;88&gt;^O&lt;93&gt;°ËÓ^BÖ&lt;83&gt;mêTyx¡/8&lt;8e&gt;-¾gó&lt;89&gt;ì\n",
    "&lt;8b&gt;^PáIwQ¨^@ó&lt;8d&gt;ë&lt;8d&gt;´J^TµÆ)F¬pBö§^P&lt;87&gt;Ì·Æµn´&lt;89&gt;²%øªñu2n3À^M^F^^eÐ±Yè&lt;84&gt;x&amp;ó°ì¼ì!^Vë&lt;81&gt;U^YÔ&lt;8f&gt;AÄQÍ¤&lt;8d&gt;&lt;9e&gt;¼zÖ&lt;88&gt;þPB^NQµú~^[xB&lt;8a&gt;'&lt;9b&gt;^M3²&lt;98&gt;ÂM^F©dS¦û&lt;9e&gt;xÐ´®;^OZâ¹L&lt;81&gt;S^T÷&nbsp;\n",
    "æ&lt;87&gt;ü(»S^N^S¢&lt;93&gt;^QD²Á¼X^]³&lt;8e&gt;q¢Â&gt;³FjÆvú&nbsp;:Å¾¬&lt;8c&gt;&lt;8a&gt;2&lt;98&gt;^PNûÍÆ'&lt;93&gt;ßÑ=ða^HÖI}òÇ8É&nbsp;jäÍ&lt;89&gt;ÕÈ^Y¶&lt;Y^G7¢ë}?#úwÆoñ´!&lt;99&gt;£V¥é^_¶&lt;94&gt;Ì&lt;90&gt;K1^P&lt;83&gt;]^l»e^YadÌõØl^UÕ&lt;8d&gt;sdpèt&lt;97&gt;^ATNô+åiçt=ÅO&lt;85&gt;^Uì=%&gt;Ú$tB^P½e7&lt;88&gt;Ær&lt;90&gt;IìK!2ÝîSÆÀ&lt;97&gt;_ÃÒ&lt;82&gt;áìÛu¶ö!^@^Y8É®6^[Ù&lt;9b&gt;ÍLX¤ËyØÜ$q^RñäI&amp;b|Å¾.^G^Sô^@óÕDl^R&lt;84&gt;i^D¨ö¯Ø&lt;9e&gt;¬é&lt;8a&gt;^S&lt;91&gt;Ñ*ê_^LÁ&lt;88&gt;&lt;9a&gt;hòÐ&lt;96&gt;tÉ%ÚÇ&lt;9f&gt;Ö@?äT&lt;86&gt;7^UH#Þ^\\£g^G&lt;86&gt;3ô,;Ûü&lt;9d&gt;&lt;80&gt;&lt;8d&gt;s_p}Æ&lt;9c&gt;ZN&lt;80&gt;ÇËuLoÊÍlâ&lt;91&gt;N^Dy£96&lt;96&gt;ãYgP&lt;8a&gt;ø^VÄõ.ì8¹\n",
    "&lt;80&gt;^OÔûâ^N!^R&nbsp;\n",
    "¼ßÓúT=&lt;80&gt;^D¡t&lt;8c&gt;~Bõ&nbsp;&nbsp;\n",
    "^Mírh^]­y}IÆ&lt;9f&gt;ûÁ&amp;êTæ@^Ví^Q'ì^B³$^^XPz½]Ë½Pù0^B²ÄÇg^Hê^@q&lt;86&gt;&lt;9f&gt;)ïsè²[°.&lt;83&gt;4Ã7Ù\n",
    "                                                                                                                \n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METADATA\n",
    "---\n",
    "Using PyPDF2 to Parse PDF Metadata\n",
    "---\n",
    "Let’s use Python to quickly recreate the forensic investigation of a document that proved useful in the arrest of a member of the hacker group Anonymous. \n",
    "\n",
    "Note\n",
    "---\n",
    "use pip to install PyPDF2\n",
    "\n",
    "<code>\n",
    "shell > pip install PyPDF2\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Creator': 'Writer', '/Author': 'Alex Tapanaris', '/Producer': 'OpenOffice.org 3.2', '/CreationDate': \"D:20101210031827+02'00'\"}\n"
     ]
    }
   ],
   "source": [
    "# Row data information, dictionary data\n",
    "from PyPDF2 import PdfFileReader\n",
    "pdf_toread = PdfFileReader(open(\"src/ANONOPS_The_Press_Release.pdf\", \"rb\"))\n",
    "pdf_info = pdf_toread.getDocumentInfo()\n",
    "print(str(pdf_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Producer': 'TeXmacs 1.99.4 + Hummus', '/Author': 'cch', '/Title': 'bank.tm', '/Creator': 'TeXmacs 1.99.4'}\n"
     ]
    }
   ],
   "source": [
    "# Row data information, dictionary data\n",
    "from PyPDF2 import PdfFileReader\n",
    "pdf_toread = PdfFileReader(open(\"../../../../../../Desktop/bank.pdf\", \"rb\"))\n",
    "pdf_info = pdf_toread.getDocumentInfo()\n",
    "print(str(pdf_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Producer': ''}\n"
     ]
    }
   ],
   "source": [
    "# Row data information, dictionary data\n",
    "from PyPDF2 import PdfFileReader\n",
    "pdf_toread = PdfFileReader(open(\"../../../../../../Downloads/掃描0002.pdf\", \"rb\"))\n",
    "pdf_info = pdf_toread.getDocumentInfo()\n",
    "print(str(pdf_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../../../../../Downloads/*.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not easy to read the dict-type data, use python to finalize the data:\n",
    "\n",
    "```\n",
    "Dict Type:\n",
    "   data={key1:value1, key2:val2,...}\n",
    "-> data[key1] = value1\n",
    "```\n",
    "Python solution:\n",
    "```Python\n",
    "   data = (dict type ...)\n",
    "   for item in data:\n",
    "       print('[+] ' + item + ':' + data[item])\n",
    "                       ꜛ              ꜛ   \n",
    "                      key           value\n",
    " ```      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "def printMeta(fileName):\n",
    "    pdfFile = PdfFileReader(open(fileName, 'rb'))\n",
    "    docInfo = pdfFile.getDocumentInfo()\n",
    "    print('[*] PDF MetaData For: ' + str(fileName))\n",
    "    for metaItem in docInfo:\n",
    "        print('[+] ' + metaItem + ':' + docInfo[metaItem])\n",
    "\n",
    "\n",
    "def pdfRead(fileName):\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "    printRead(File)\n",
    "    \n",
    "    For example,\n",
    "        pdfRead('where/file.pdf')\n",
    "    \"\"\"    \n",
    "    printMeta(fileName)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pdfRead in module __main__:\n",
      "\n",
      "pdfRead(fileName)\n",
      "    Usage:\n",
      "    printRead(File)\n",
      "    \n",
      "    For example,\n",
      "        pdfRead('where/file.pdf')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pdfRead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] PDF MetaData For: src/ANONOPS_The_Press_Release.pdf\n",
      "[+] /Creator:Writer\n",
      "[+] /Author:Alex Tapanaris\n",
      "[+] /Producer:OpenOffice.org 3.2\n",
      "[+] /CreationDate:D:20101210031827+02'00'\n"
     ]
    }
   ],
   "source": [
    "#pdfRead('SeniorCitizens.pdf')\n",
    "pdfRead('src/ANONOPS_The_Press_Release.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze Web Images\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request, urllib.error, urllib.parse\n",
    "import optparse\n",
    "from urllib.parse import urlsplit\n",
    "from os.path import basename\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "\n",
    "def findImages(url):\n",
    "    print('[+] Finding images on ' + url)\n",
    "    urlContent = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(urlContent)\n",
    "    imgTags = soup.findAll('img')\n",
    "    return imgTags\n",
    "\n",
    "\n",
    "def downloadImage(imgTag):\n",
    "    try:\n",
    "        print('[+] Dowloading image...')\n",
    "        imgSrc = imgTag['src']\n",
    "        imgContent = urllib.request.urlopen(imgSrc).read()\n",
    "        imgFileName = basename(urlsplit(imgSrc)[2])\n",
    "        imgFile = open(imgFileName, 'wb')\n",
    "        imgFile.write(imgContent)\n",
    "        imgFile.close()\n",
    "        return imgFileName\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def testForExif(imgFileName):\n",
    "    try:\n",
    "        exifData = {}\n",
    "        imgFile = Image.open(imgFileName)\n",
    "        info = imgFile._getexif()\n",
    "        if info:\n",
    "            for (tag, value) in list(info.items()):\n",
    "                decoded = TAGS.get(tag, tag)\n",
    "                exifData[decoded] = value\n",
    "            exifGPS = exifData['GPSInfo']\n",
    "            if exifGPS:\n",
    "                print('[*] ' + imgFileName + \\\n",
    "                 ' contains GPS MetaData')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    imgTags = findImages(url)\n",
    "    for imgTag in imgTags:\n",
    "        imgFileName = downloadImage(imgTag)\n",
    "        testForExif(imgFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Finding images on http://flicker.com/photos/dvids/4999001925/sizes/o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cch/anaconda/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/cch/anaconda/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Dowloading image...\n",
      "[+] Dowloading image...\n",
      "[+] Dowloading image...\n",
      "[*] 4999001925_ab6da92710_o.jpg contains GPS MetaData\n",
      "[+] Dowloading image...\n",
      "[+] Dowloading image...\n"
     ]
    }
   ],
   "source": [
    "url=\"http://flicker.com/photos/dvids/4999001925/sizes/o\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing Firefox Sqlite3 Databases\n",
    "---\n",
    "\n",
    "[Link: Mozilla Firefox, sqlite DB, http://forensicswiki.org/wiki/Mozilla_Firefox](http://forensicswiki.org/wiki/Mozilla_Firefox)\n",
    "\n",
    "Firefox stores these databases in a default directory located at \n",
    "\n",
    "- Windows: <code style=\"color:brown\">C:\\Documents and Settings\\<USER>\\Application Data\\Mozilla\\Firefox\\Profiles\\&lt;profile folder&gt;\\</code>\n",
    "- MacOS: <code style=\"color:blue\">/Users/&lt;USER&gt;/Library/Application Support/Firefox/Profiles/&lt;profile&gt;/</code>\n",
    "\n",
    "The data files in  sqlite format include:\n",
    "<code style=\"background-color:black;color:yellow\">\n",
    "addons.sqlite formhistory.sqlite signons.sqlite places.sqlite\n",
    "content-prefs.sqlite healthreport.sqlite  webappsstore.sqlite\n",
    "cookies.sqlite\t\tpermissions.sqlite    extensions.sqlite\t\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Cookies\n",
    "---\n",
    "\n",
    "Consider, for example, when a user logs onto a web-based email: if the browser could not maintain cookies, the user would have to log on in order to read every individual email. Firefox stores these cookies in a database named <font color=\"green\">cookies.sqlite</font>. If an investigator can extract cookies and reuse them, it provides the opportunity to log on to resources that require authentication.\n",
    "\n",
    "<code style=\"color:blue\">\n",
    "                                No                                                           \n",
    "    |----------|   cookies? |-------->   log on to read mail                                \n",
    "    | web-basd |  ----------|                                                                \n",
    "    |  Email   |            |-------->   get data in cookies.sqlite to login automatically   \n",
    "    |----------|               Yes                                                            \n",
    "       \n",
    "</code>\n",
    "\n",
    "\n",
    "\n",
    "Let’s write a quick Python script to extract cookies from a user under investigation. We connect to the database and execute our SELECT statement. In the database, the moz_cookies maintains the data regarding cookies. From the moz_cookies table in the cookies.sqlite database, we will query the column values for host, name, and cookie value, and print them to the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the sqlite is created as binany, part of <font color=\"green\">downloads.sqlite</font> should give the details of table what it owns:\n",
    "<code style=\"color:blue\">\n",
    "...\n",
    "CREATE TABLE moz_downloads (id INTEGER PRIMARY KEY, name TEXT, source TEXT, target TEXT, tempPath TEXT, startTime INTEGER, endTime INTEGER, state INTEGER, referrer TEXT, entityID TEXT, currBytes INTEGER NOT NULL DEFAULT 0, maxBytes INTEGER NOT NULL DEFAULT -1, mimeType TEXT, preferredApplication TEXT, preferredAction INTEGER NOT NULL DEFAULT 0, autoResume INTEGER NOT NULL DEFAULT 0)\n",
    "...\n",
    "</code>\n",
    "i.e. the details of created table and its columns are listed as follows:\n",
    "<code style=\"color:brown\">\n",
    "Table\n",
    "  moz_downloads\n",
    "  Columns: type/value\n",
    "      id: INTEGER (PRIMARY KEY),\n",
    "      name: TEXT,\n",
    "      source: TEXT,\n",
    "      target: TEXT,\n",
    "      tempPath: TEXT, \n",
    "      startTime: INTEGER, \n",
    "      endTime: INTEGER, \n",
    "      state: INTEGER, \n",
    "      referrer: TEXT,\n",
    "      entityID TEXT,\n",
    "      currBytes INTEGER NOT NULL DEFAULT 0, \n",
    "      maxBytes INTEGER NOT NULL DEFAULT -1, \n",
    "      mimeType TEXT, \n",
    "      preferredApplication TEXT, \n",
    "      preferredAction INTEGER NOT NULL DEFAULT 0, \n",
    "      autoResume INTEGER NOT NULL DEFAULT 0\n",
    "</code>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investingate the Sqlite Data\n",
    "---\n",
    "- use `Sqlite` library:\n",
    "<code style=\"color:blue\">\n",
    "shell> sqlite3 cookies.sqlite\n",
    "SQLite version 3.13.0 2016-05-18 10:57:30\n",
    "Enter \".help\" for usage hints.\n",
    "sqlite> select * from moz_cookies;\n",
    "1|google.com||__utma|29003808.1143615086.1386662234.1386662234.1386662234.1|.mail.google.com|/intl/|1449734236|1386662236729073|1386662233628573|0|0|0|0\n",
    "2|google.com||__utmb|29003808.2.9.1386662236726|.mail.google.com|/intl/|1386664036|1386662236729451|1386662233628903|0|0|0|0\n",
    "...\n",
    "</code>\n",
    "- by Pyhon's sqlite3 library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def printDownloads(downloadDB):\n",
    "    conn = sqlite3.connect(downloadDB)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT name, source, datetime(endTime/1000000,\\\n",
    "    \\'unixepoch\\') FROM moz_downloads;'\n",
    "              )\n",
    "    print('\\n[*] --- Files Downloaded --- ')\n",
    "    for row in c:\n",
    "        print('[+] File: ' + str(row[0]) + ' from source: ' \\\n",
    "            + str(row[1]) + ' at: ' + str(row[2]))    \n",
    "\n",
    "def printCookies(cookiesDB):\n",
    "    try:\n",
    "        conn = sqlite3.connect(cookiesDB)\n",
    "        c = conn.cursor()\n",
    "        c.execute('SELECT host, name, value FROM moz_cookies')\n",
    "\n",
    "        print('\\n[*] -- Found Cookies --')\n",
    "        for row in c:\n",
    "            host = str(row[0])\n",
    "            name = str(row[1])\n",
    "            value = str(row[2])\n",
    "            print('[+] Host: ' + host + ', Cookie: ' + name \\\n",
    "                + ', Value: ' + value)\n",
    "    except Exception as e:\n",
    "        if 'encrypted' in str(e):\n",
    "            print('\\n[*] Error reading your cookies database.')\n",
    "            print('[*] Upgrade your Python-Sqlite3 Library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*] --- Files Downloaded --- \n",
      "[+] File: python-nmap-0.1.4.tar.gz from source: http://xael.org/norman/python/python-nmap/python-nmap-0.1.4.tar.gz at: 2012-06-20 02:53:09\n"
     ]
    }
   ],
   "source": [
    "printDownloads('firefox_profile/downloads.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printCookies('Cookies.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An investigator may also wish to enumerate the browser history. Firefox stores this data in a database named places.sqlite. Here, the moz_places table gives us valuable columns that include information about when (date) and where (address) a user visited a site. While our script for printHistory() only takes into account the moz_places table, the ForensicWiki Web site recommends using data from both the moz_places table and the moz_historyvisits table as well to get a live browser history (Forensics Wiki, 2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printHistory(placesDB):\n",
    "    try:\n",
    "        conn = sqlite3.connect(placesDB)\n",
    "        c = conn.cursor()\n",
    "        c.execute(\"select url, datetime(visit_date/1000000, \\\n",
    "          'unixepoch') from moz_places, moz_historyvisits \\\n",
    "          where visit_count > 0 and moz_places.id==\\\n",
    "          moz_historyvisits.place_id;\")\n",
    "\n",
    "        print('\\n[*] -- Found History --')\n",
    "        for row in c:\n",
    "            url = str(row[0])\n",
    "            date = str(row[1])\n",
    "            print('[+] ' + date + ' - Visited: ' + url)\n",
    "    except Exception as e:\n",
    "        if 'encrypted' in str(e):\n",
    "            print('\\n[*] Error reading your places database.')\n",
    "            print('[*] Upgrade your Python-Sqlite3 Library')\n",
    "            exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printHistory('places.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Analyze-Browsing-History,--Recognize-Ourselves](History_Analyze.ipynb)\n",
    "\n",
    "Practice on Google Chrome Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('C:\\Users\\[username]\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\History', 'rb')\n",
    "data = f.read()\n",
    "f.close()\n",
    "f = open('your_expected_file_path', 'w')\n",
    "f.write(repr(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def printGoogle(placesDB):\n",
    "    conn = sqlite3.connect(placesDB)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"select url, datetime(visit_date/1000000, \\\n",
    "      'unixepoch') from moz_places, moz_historyvisits \\\n",
    "      where visit_count > 0 and moz_places.id==\\\n",
    "      moz_historyvisits.place_id;\")\n",
    "\n",
    "    print('\\n[*] -- Found Google --')\n",
    "    for row in c:\n",
    "        url = str(row[0])\n",
    "        date = str(row[1])\n",
    "        if 'google' in url.lower():\n",
    "            r = re.findall(r'q=.*\\&', url)\n",
    "            if r:\n",
    "                search=r[0].split('&')[0]\n",
    "                search=search.replace('q=', '').replace('+', ' ')\n",
    "                print('[+] '+date+' - Searched For: ' + search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use the last example and our knowledge of regular expressions to expand the previous function. While browser history is in nitely valuable, it would be useful to look deeper into some of the speci c URLs visited. Google search queries contain the search terms right inside of the URL, for example. In the wireless section, we will expand on this in great depth. However, right now, let’s just extract the search terms right out of the URL. If we spot a URL in our history that contains Google, we will search it for the characters `q=` followed by an `&`. This speci c sequence of characters indicates a Google search. If we do  nd this term, we will clean up the output by replacing some of the characters used in URLs to pad whitespace with actual whitespace. Finally, we will print out the corrected output to the screen. Now we have a function that can search the places.sqlite  le for and print out Google search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGoogle('places.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INVESTIGATING ITUNES MOBILE BACKUPS \n",
    "---\n",
    "In April 2011, security researcher and former Apple employee Pete Warden disclosed a privacy issue with the popular Apple iPhone/Ipad iOS operating system (Warden, 2011). After a significant investigation, Mr. Warden revealed proof that the Apple iOS operating system actually tracked and recorded the GPS coordinates of the device and stored them in a database on the phone called `consolidated.db` (Warden, 2011). Inside this database, a table named Cell-Location contained the GPS points the phone had collected. The device determined the location information by triangulating off the nearest cell-phone towers in order to provide the best service for the device user. However, as Mr. Warden suggested, this same data could be used maliciously to track the entire movements an iPhone/iPad user. Furthermore, the process used to backup and store a copy of the mobile device to a computer also recorded this information. While the location-recording information has been removed from the Apple iOS operating system functionality, the process Mr. Warden used to discover the data remains. In this section, we will repeat this process to extract information from iOS mobile device backups. Specifically, we will extract all the text messages out of an iOS backup using a Python script.\n",
    "\n",
    "```\n",
    "~/Library/Application Support/MobileSync/Backup\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def isMessageTable(iphoneDB):\n",
    "    try:\n",
    "        conn = sqlite3.connect(iphoneDB)\n",
    "        c = conn.cursor()\n",
    "        c.execute('SELECT tbl_name FROM sqlite_master \\\n",
    "          WHERE type==\\\"table\\\";')\n",
    "        for row in c:\n",
    "            if 'message' in str(row):\n",
    "                return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def printMessage(msgDB):\n",
    "    try:\n",
    "        conn = sqlite3.connect(msgDB)\n",
    "        c = conn.cursor()\n",
    "        c.execute('select datetime(date,\\'unixepoch\\'),\\\n",
    "          address, text from message WHERE address>0;')\n",
    "        for row in c:\n",
    "            date = str(row[0])\n",
    "            addr = str(row[1])\n",
    "            text = row[2]\n",
    "            print('\\n[+] Date: '+date+', Addr: '+addr \\\n",
    "                + ' Message: ' + text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def iphoneMessage(pathName):\n",
    "    dirList = os.listdir(pathName)\n",
    "    for fileName in dirList:\n",
    "        iphoneDB = os.path.join(pathName, fileName)\n",
    "        if isMessageTable(iphoneDB):\n",
    "            try:\n",
    "                print('\\n[*] --- Found Messages ---')\n",
    "                printMessage(iphoneDB)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try\n",
    "```\n",
    "iphoneMessage('where-the backup-dircetory')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c6bc5410aba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_days\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstart_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mend_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "import plistlib, os.path, datetime, pytz, tzlocal, sys\n",
    "\n",
    "\n",
    "_, start_days, end_days = sys.argv\n",
    "start_days = int(start_days)\n",
    "end_days = int(end_days)\n",
    "\n",
    "\n",
    "\n",
    "apple_epoch = datetime.datetime(\n",
    "\t2001, 1, 1, 0, 0, 0, 0,\n",
    "\ttzinfo=pytz.timezone('UTC')\n",
    ")\n",
    "def parse_apple_time(apple_time):\n",
    "\treturn apple_epoch + datetime.timedelta(\n",
    "\t\tseconds=float(apple_time)\n",
    "\t)\n",
    "\n",
    "\n",
    "local_tz = tzlocal.get_localzone()\n",
    "def to_local(when):\n",
    "\treturn when.astimezone(\n",
    "\t\tlocal_tz\n",
    "\t)\n",
    "\n",
    "\n",
    "class Item:\n",
    "\tdef __init__(self, data):\n",
    "\t\tself.when = parse_apple_time(data['lastVisitedDate'])\n",
    "\t\tself.title = data.get('title', '')\n",
    "\t\tself.address = data['']\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn '%s\\t%s' % (to_local(self.when), self.title)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_history():\n",
    "\n",
    "\thistory = plistlib.load(\n",
    "\t\topen(os.path.expanduser('~/library/Safari/History.plist'), 'rb')\n",
    "\t)['WebHistoryDates']\n",
    "\n",
    "\titems = []\n",
    "\n",
    "\tfor data in history:\n",
    "\n",
    "\t\titems.append(Item(data))\n",
    "\n",
    "\n",
    "\treturn items\n",
    "\n",
    "\n",
    "history = load_history()\n",
    "history = filter( lambda _: datetime.date.today() + datetime.timedelta(days=start_days) <= to_local(_.when).date() <= datetime.date.today() + datetime.timedelta(days=end_days), history )\n",
    "history = sorted( history, key=lambda _: _.when )\n",
    "\n",
    "\n",
    "#for item in sorted(filter(load_history(), lambda _: to_local(_.when).day() < datetime.date.today()), key=lambda _: _.when):\n",
    "#\tprint(item)\n",
    "\n",
    "for item in history:\n",
    "\tprint(item)\n",
    "\n",
    "\n",
    "\n",
    "#print('\\n'.join('%s\\t%s' % ((datetime.datetime(2001, 1, 1, 0, 0, 0, 0,tzinfo=pytz.timezone('UTC')) + datetime.timedelta(seconds=float(_['lastVisitedDate']))).astimezone(tzlocal.get_localzone()),_.get('title','')) \n",
    "#\tfor _ in plistlib.load(open(os.path.expanduser('~/library/Safari/History.plist'), 'rb'))['WebHistoryDates'])\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import plistlib\n",
    "\n",
    "def main():\n",
    "\n",
    "   fileName=os.path.expanduser('Downloads.plist')\n",
    "   \n",
    "   if os.path.exists(fileName):\n",
    "\n",
    "      pl=plistlib.readPlist(fileName)\n",
    "   \n",
    "      print('\\nThe plist full contents is %s\\n' % pl)\n",
    "\n",
    "      if 'aString' in pl:\n",
    "         print('The aString value is %s\\n' % pl['aString'])\n",
    "      else:\n",
    "         print('There is no aString in the plist\\n')\n",
    "\n",
    "   else:\n",
    "      print('%s does not exist, so can\\'t be read' % fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cch/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: DeprecationWarning: The readPlist function is deprecated, use load() instead\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'aKey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a14b08e5811a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplistlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadPlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloads.plist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"aKey\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'aKey'"
     ]
    }
   ],
   "source": [
    "pl = plistlib.readPlist(\"Downloads.plist\")\n",
    "item = pl[\"aKey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
